package org.example

import com.typesafe.config.{Config, ConfigFactory}
import org.apache.log4j.{Level, Logger}
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.expressions.Window
import org.apache.spark.sql.functions._

import java.time.format.DateTimeFormatter
import java.time.{LocalDate, LocalDateTime}



object question1 extends App {
  // /////////////////////////////////////////////
  // Spark Session
  ///////////////////////////////////////////////
  val spark = SparkSession.builder
    .appName("sapient_questions") // optional and will be autogenerated if not specified
    .master("local[*]") // only for demo and testing purposes, use spark-submit instead
    .getOrCreate

  ///////////////////////////////////////////////
  // Spark configs and initial variables
  ///////////////////////////////////////////////
  val configs: Config = ConfigFactory.load("properties.conf")

  // Read Input Data (lazy)
  val inputFileQ1 = configs.getString("paths.q1data")
  val inputFileQ2 = configs.getString("paths.q2data")
  val inputFileQ3 = configs.getString("paths.q3data")

  // Output locations
  val outputLocQ2 = configs.getString("paths.q1outlocation")

  val inpDF1 = spark.read
    .option("header", true)
    .csv(s"$inputFileQ1")

  val inpDF2 = spark.read
    .option("header", true)
    .csv(s"$inputFileQ2")

  /*val inpDF3 = spark.read
      .option("header",true)
      .csv(s"$inputFileQ3")*/

  // Logger
  val rootLogger = Logger.getRootLogger
  rootLogger.setLevel(Level.ERROR)

  // Date and Time Variables
  val dateToday = LocalDate.now()
  val TimeToday = LocalDateTime.now()
  val dateFormat = "ddMMYYYY"
  val fmtYear = "YYYY"
  val fmtMonth = "MM"
  val fmtDay = "dd"
  val TimeStampFormat = "ddMMYYYY"

  val formattedDate = dateToday.format(DateTimeFormatter.ofPattern("ddMMYYYY"))
  val formattedTime=  TimeToday.format(DateTimeFormatter.ofPattern("YYYY-MM-dd HH:mm:ss"))
  val tsFormat: String = "2018-01-01T12:15:00Z"
//  val formattedTime1= tsFormat.format(DateTimeFormatter.ofPattern(s"$TimeStampFormat"))

  ////////////////////////////////////
  // Logic for Solution 1
  ////////////////////////////////////
  rootLogger.info("---Solution 1---")
  println("---Solution 1---")
  inpDF1.dropDuplicates("Name", "Age").show()


  ////////////////////////////////////
  // Logic for Solution 2
  ////////////////////////////////////
  val formattedDF2 = UserDefinedFunctions.changeColType(inpDF2,"timestamp","Timestamp")

  val windowSpec = Window.partitionBy("userid").orderBy("timestamp")
  val LeadWindowOverTs = lead(col("timestamp"), 1).over(windowSpec)
//  val LeadRunningWindowOverSession = lag((col("session_id")), 1).over(windowSpec)
  val inputDf2WithNextTimestamp= formattedDF2.withColumn("next_timestamp",LeadWindowOverTs)
  inputDf2WithNextTimestamp.printSchema()
  inputDf2WithNextTimestamp.show()
  val inputDf2WithNextTimestampAndDuration = inputDf2WithNextTimestamp
                                                   .withColumn("duration",UserDefinedFunctions.sessionDuration(unix_timestamp(col("timestamp")),unix_timestamp(col("next_timestamp"))))
                                                   .drop("next_timestamp").na.fill(Map("duration" -> 0))
                                                   .select("userid","timestamp","duration")
  //Persist
  inputDf2WithNextTimestampAndDuration.persist()

  val inputDf2WithSessionId = inputDf2WithNextTimestampAndDuration.withColumn("session_id",UserDefinedFunctions.assignSessionId(col("duration")) )

  println("---Solution 2---")
  val q2SolutionDf = inputDf2WithSessionId.drop("duration")
  q2SolutionDf.write.mode("overwrite").parquet(outputLocQ2)
  q2SolutionDf.show(false)
  println(s"---The output to Sol2 has been written to $outputLocQ2---")


  ////////////////////////////////////
  // Logic for Solution 3
  ////////////////////////////////////
  println("---Solution 3---")
  inputDf2WithNextTimestampAndDuration.show(false)

  //Number of sessions generated in a day.
//  val totalSessionsGeneratedInADay = q2SolutionDf.groupBy(col("userid"),col("session_id")).count()
//  val CountOfSessionsGeneratedInADay = q2SolutionDf.drop(col("timestamp")).distinct().count()
//  val CountOfSessionsGeneratedInADay = q2SolutionDf.dropDuplicates("userid","session_id").count()
//  println(s"Count of Sessions Generated in a Day (Sol-3-a): $CountOfSessionsGeneratedInADay")

  val q3SolutionDf = inputDf2WithNextTimestampAndDuration
                     .withColumn("event_year",year(col("timestamp")))
                     .withColumn("event_month",month(col("timestamp")))
                     .withColumn("event_day",dayofmonth(col("timestamp")))
  q3SolutionDf.show()

  //Total time spent by a user in a day

  //Total time spent by a user over a month.


  //Un-persist
  inputDf2WithNextTimestampAndDuration.unpersist()

spark.stop()



}
